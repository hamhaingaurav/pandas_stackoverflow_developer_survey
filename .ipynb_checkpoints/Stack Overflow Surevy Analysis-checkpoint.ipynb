{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## to create a dataframe using python dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actors = {\n",
    "        'Name':['Samuel L. Jackson','Will Smith','Denzel Washington','Morgan Freeman'],\n",
    "        'Age':[71,51,65,83],\n",
    "    }\n",
    "actors_df = pd.DataFrame(actors,index=['a','b','c','d'])\n",
    "actors_df\n",
    "# type(actors_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## to create a series using python lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actors_series = pd.Series(['Samuel L. Jackson','Will Smith','Denzel Washington','Morgan Freeman'])\n",
    "actors_series\n",
    "type(actors_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pd.read_csv() to read the csv file, We also have pd.read_sql(), pd.read_excel(), pd.read_html(), pd.read_json() and much more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"developer_survey_2019/survey_results_public.csv\")\n",
    "schema_df = pd.read_csv(\"developer_survey_2019/survey_results_schema.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df\n",
    "# schema_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total Number of Rows and Columns Respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"(Rows, Columns) =\",df.shape)\n",
    "print(\"(Rows, Columns) =\",schema_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get more information about Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.info())\n",
    "# In pandas, Object represets string most of the time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To show all the columns of a dataset at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns',85)\n",
    "pd.set_option('display.max_rows',85)\n",
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of columns and its names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df.columns\n",
    "n_cols = len(df.columns)\n",
    "print(\"Total Columns: \",n_cols)\n",
    "print(\"Column Names: \",cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show the top 5 rows of dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()  \n",
    "\n",
    "# You can also pass some number inside head to show given number of rows\n",
    "# df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show the bottom 5 rows of dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()\n",
    "\n",
    "# You can also pass some number inside tail to show given number of rows\n",
    "# df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select a Specific Column by three ways\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "respondent = df.Respondent\n",
    "respondent_ = df['Respondent']\n",
    "respondent__ = df.loc[:,'Respondent']\n",
    "print(\"First Result: \\n\",respondent)\n",
    "print(\"\\nSecond Result: \\n\",respondent_)\n",
    "print(\"\\nThird Result: \\n\",respondent__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Multiple Columns or Specific Columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[['Respondent','EdLevel','Student','Country',...................]]\n",
    "df[['Respondent','EdLevel','Student','Country']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loc vs iloc(it only uses integers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iloc\n",
    "df.iloc[0]  # First Row\n",
    "df.iloc[[0,1,2]] # First, Second and Third rows of df\n",
    "df.iloc[[0,1,2],0] # First, Second and Third rows with First column of df\n",
    "df.iloc[[0,1,2],[0,1,2,84]] # First, Second and Third rows with first,second,third and 85th column of df\n",
    "df.iloc[:3,:19] # row 1st to row 3rd with all columns till 19th column including 19th column of df\n",
    "df.iloc[[0,1,2],:19] # First, Second and Third rows with all columns till 19th column including 19th column of df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loc\n",
    "# Note: slicing in loc is always inclusive, it does not follow pyhton slicing rule.\n",
    "df.loc[0]  # First Row (We are putting 0 because we have an index with 0)\n",
    "df.loc[[0,1,2]] # First, Second and Third rows of df\n",
    "df.loc[[0,1,2],'Respondent'] # First, Second and Third rows with First column of df\n",
    "df.loc[[0,1,2],['Respondent','MainBranch','Hobbyist','SurveyEase']] # First, Second and Third rows with first,second,third and 85th column of df\n",
    "df.loc[:2,'Respondent'] # row 1st to row 3rd with Respondent column of df\n",
    "df.loc[[0,1,2],['Respondent','MainBranch','Hobbyist', 'SurveyEase']] # First, Second and Third rows with 'Respondent','MainBranch','Hobbyist','SurveyEase' columns of df\n",
    "df.loc[:2,'MainBranch':'Student'] # First, Second and Third rows with columns from MainBranch to Student of df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index\n",
    "\n",
    "# to change the index to another column, we can use set_index() method\n",
    "df.set_index('Respondent') \n",
    "# set_index() will return the df with new index, it will not change the df until we pass the arguement inplace=True.\n",
    "df.set_index('Respondent',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to reset the index we can use reset_index() with or without reset_index(inplace=True)\n",
    "df.reset_index()\n",
    "# or\n",
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to sort index we can use sort_index() with or without inplace=True\n",
    "new_df = df.loc[:10,['Respondent','MainBranch','Hobbyist', 'SurveyEase']]\n",
    "new_df_ = new_df.set_index('MainBranch')\n",
    "new_df_sorted = new_df_.sort_index()\n",
    "new_df_sorted # alphabetically sorted df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering the Data using conditionals and some inbuilt functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_1 = (df['Hobbyist'] == 'No')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[filter_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_2 = (df['Country']=='India') & (df['Student']=='No')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[filter_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_3 = (df['Country']=='India') | (df['Country']=='Canada')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[filter_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[~filter_3]   # < ~ > symbol is used to reverse the out put, it is very similar to python not keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_salary_filter = (df['ConvertedComp'] > 100000) & (df['Country']=='India')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[high_salary_filter,['Respondent','OpenSourcer','Student','EdLevel','DevType','YearsCodePro']].set_index('Respondent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isin() function to filter using lists\n",
    "high_salary_df = df.loc[high_salary_filter,['Respondent','Country','OpenSourcer','Student','EdLevel','DevType','YearsCodePro']].set_index('Respondent')\n",
    "high_salary_with_specific_country_filter = high_salary_df['Country'].isin(['India','United States','Canada'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "high_salary_df[high_salary_with_specific_country_filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we are going to find out whome of them actually worked with Python\n",
    "\n",
    "python_filter = df['LanguageWorkedWith'].str.contains('Python',na=False) # we have put na=False to avoind na values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[python_filter,['Respondent','Country','Student','LanguageWorkedWith']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modifying Rows and Columns in Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to make all the column names to lower case\n",
    "df.columns = [x.lower() for x in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to make all the column names to upper case\n",
    "df.columns = [x.upper() for x in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# to rename the column names with df.rename() method\n",
    "df.rename(columns={'Respondent':'Res'}) # to make this change permanent we can pass inplace=True in rename method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to replace some values of a row or column we can use df.at() method, we can also use .loc but at if prefered method\n",
    "df.loc[0,'Respondent'] = 1\n",
    "df.at[0,'Respondent'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## apply, map, applymap, replace methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .apply() works on both df and series,this function is used to -\n",
    "# apply a function into each series of a dataframe and \n",
    "# apply a function into each element of a series \n",
    "\n",
    "def db_names(row):\n",
    "    db_list = str(row).split(';')\n",
    "    return db_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the string of databses seperated with ; ,to a list\n",
    "df['DatabaseWorkedWith'] = df['DatabaseWorkedWith'].apply(db_names)\n",
    "df['DatabaseWorkedWith']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# above thing using lambda function\n",
    "df['DatabaseWorkedWith'] = df['DatabaseWorkedWith'].apply(lambda s: str(s).split(';'))\n",
    "df['DatabaseWorkedWith']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applymap() function is used to apply a function to every element of a df, it only works on df\n",
    "df.applymap(lambda x: len(str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map() method is used to map new values to old values\n",
    "# map() and replace() are very similar method except that map() sets the NaN where mapping is not provided\n",
    "df['Hobbyist'].map({'Yes':'No'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it just changes the values which we told it to change.\n",
    "df['Hobbyist'].replace({'Yes':'No'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add/Remove columns and rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to add columns and assign it to a new column\n",
    "df['HobbyistRespondent'] = df['Hobbyist'] + ' ' + df['Respondent'].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to remove a column we can use the drop method on df\n",
    "df.drop(columns=['HobbyistRespondent'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to expand the value of a column using str.split(expand=True)\n",
    "df['WebFrameWorkedWith'].str.split(';',expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to add a new row in the df\n",
    "df.append({'Country':'Los Santos'},ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# to remove a row in the df\n",
    "df.drop(index=0,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## combine two dataframes using append function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = {\n",
    "        'Name':['Samuel L. Jackson','Will Smith'],\n",
    "        'Age':[71,51],\n",
    "    }\n",
    "\n",
    "d2 = {\n",
    "        'Name':['Denzel Washington','Morgan Freeman'],\n",
    "        'Age':[65,83],\n",
    "    }\n",
    "\n",
    "df1 = pd.DataFrame(d1)\n",
    "df2 = pd.DataFrame(d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.append(df2,ignore_index=True) #ignore_index=True to avoid the repetition of index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sort by a single column\n",
    "df.sort_values(by='Country',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by multiple columns\n",
    "df.sort_values(by=['Hobbyist','Country','Respondent'],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by one column to be ascending but another to be descending columns\n",
    "df.sort_values(by=['Hobbyist','Country','Respondent'],ascending=[False,False,True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to sort the index\n",
    "df.sort_index(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also sort the series using sort_values() method\n",
    "df['Hobbyist'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort values using multiple columns\n",
    "df.sort_values(by=['Country','ConvertedComp'],ascending=[True,False],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the max values of salaries based on the country as index\n",
    "df[['Country','ConvertedComp']].groupby(['Country']).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlargest method to get top n largest values of a dataframe or seies\n",
    "df[['Country','ConvertedComp']].nlargest(10,columns=['ConvertedComp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nsmallest method to get top n smallest values of a dataframe or seies\n",
    "df[['Country','ConvertedComp']].nsmallest(10,columns=['ConvertedComp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the result who have salary greater than 1\n",
    "df[['Country','ConvertedComp']].loc[df['ConvertedComp']>1].nsmallest(10,columns=['ConvertedComp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping and Aggregating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# median() method\n",
    "df['ConvertedComp'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean() method\n",
    "df['ConvertedComp'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min() method\n",
    "df['ConvertedComp'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# median() method\n",
    "df['ConvertedComp'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count() method\n",
    "df['Hobbyist'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# value_counts() method\n",
    "df['SocialMedia'].value_counts()\n",
    "# df['SocialMedia'].value_counts(normalize=True) # we can pass normalize=True to get % values\n",
    "# df['DatabaseWorkedWith'].value_counts()\n",
    "\n",
    "# difference between counts and value_counts is that counts just count the rows where any value exists, \n",
    "# but value_counts will counts the count of individual values of that column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# to get the more statistic values of our dataset we can use .describe()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupby() is used to group the df based on provided column\n",
    "# we can also create a filter , it will also group the results based on provided country name\n",
    "# india_filter = (df['Country'] == 'India')\n",
    "# df[india_filter]\n",
    "country_group = df.groupby(['Country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_group.get_group('India')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_group() function is used for getting the values based on group indexes\n",
    "country_group.get_group('India')['SocialMedia'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_group['SocialMedia'].value_counts().loc['India']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get the more statistic values of our groups we can use .describe()\n",
    "country_group['ConvertedComp'].describe().loc['India']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also use median or any aggregate function on groupby df.\n",
    "country_group['ConvertedComp'].median().loc['India']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to apply mulitple aggregate function to a groupby df we can use agg() method\n",
    "country_group['ConvertedComp'].agg(['mean','median','min','max','std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get more specific results we can use .loc also\n",
    "country_group['ConvertedComp'].agg(['mean','median','min','max','std']).loc['India']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the % of people in each country who uses Python ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# people uses python\n",
    "respondent_uses_python = country_group['LanguageWorkedWith'].apply(lambda x: x.str.contains('Python').sum())\n",
    "respondent_uses_python['United States']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# resondents in a country\n",
    "respondetns_in_country = df['Country'].value_counts()\n",
    "respondetns_in_country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we will concatenate the total respondents df and python knows respondetn df\n",
    "python_country_df = pd.concat([respondetns_in_country,respondent_uses_python],axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# then we will rename the columns to our desired values\n",
    "python_country_df.rename(columns={'Country':'Respondent','LanguageWorkedWith':'RespondentKnowPython'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# then calculate the % of people who knows python by just dividing the values\n",
    "python_country_df['PercentageKnowPython'] = python_country_df['RespondentKnowPython']/python_country_df['Respondent']*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will sort the values in descending order\n",
    "python_country_df.sort_values(by='PercentageKnowPython',ascending=False,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the unneccesary columns\n",
    "python_country_df.drop(columns=['Respondent','RespondentKnowPython'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is our final result\n",
    "python_country_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Data and Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_with_na = df.loc[:,['Respondent','Hobbyist','Student','ConvertedComp']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropna() to remove missing values\n",
    "df_with_na.dropna()\n",
    "\n",
    "# how='any' mean if any values is 'NaN' in a row ,whole row will be removed\n",
    "df_with_na.dropna(axis='rows',how='any') # we can pass axis='columns' also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how='all' mean all values should be 'NaN' in a row if axis='rows'\n",
    "df_with_na.dropna(axis='rows',how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also pass subset to check for a specific column for NaN values\n",
    "df_with_na.dropna(axis='rows',how='all',subset=['ConvertedComp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isna() will return True False values where values are NaN\n",
    "df_with_na.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fillna() to replace the NaN values in a df or series\n",
    "df_with_na.fillna('Missing',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace method to replace the values\n",
    "df_with_na.replace('Missing',np.nan,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dtypes is used to look at the datatype of df or series\n",
    "df_with_na.dtypes.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_na.loc[:,'Respondent'].dtype\n",
    "# or\n",
    "df_with_na.loc[:,'Respondent'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dtype attribute is used to look the data type of a single element of df or series\n",
    "df_with_na.loc[1:,'Respondent'][1].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# astype method is used for converting the value to new data type\n",
    "df_with_na['Respondent'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dates and Time Series Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "crypt_df = pd.read_csv(\"cryptocurrency_data_1h.csv\")\n",
    "\n",
    "# to convert the date column during importing the data we can user these values to pass into the read_csv function\n",
    "from datetime import datetime\n",
    "crypt_df = pd.read_csv(\"cryptocurrency_data_1h.csv\", parse_dates=['Date'], date_parser = lambda d: datetime.strptime(d,'%Y-%m-%d %I-%p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-03-13 20:00:00</td>\n",
       "      <td>ETHUSD</td>\n",
       "      <td>129.94</td>\n",
       "      <td>131.82</td>\n",
       "      <td>126.87</td>\n",
       "      <td>128.71</td>\n",
       "      <td>1940673.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-03-13 19:00:00</td>\n",
       "      <td>ETHUSD</td>\n",
       "      <td>119.51</td>\n",
       "      <td>132.02</td>\n",
       "      <td>117.10</td>\n",
       "      <td>129.94</td>\n",
       "      <td>7579741.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-03-13 18:00:00</td>\n",
       "      <td>ETHUSD</td>\n",
       "      <td>124.47</td>\n",
       "      <td>124.85</td>\n",
       "      <td>115.50</td>\n",
       "      <td>119.51</td>\n",
       "      <td>4898735.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-03-13 17:00:00</td>\n",
       "      <td>ETHUSD</td>\n",
       "      <td>124.08</td>\n",
       "      <td>127.42</td>\n",
       "      <td>121.63</td>\n",
       "      <td>124.47</td>\n",
       "      <td>2753450.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-03-13 16:00:00</td>\n",
       "      <td>ETHUSD</td>\n",
       "      <td>124.85</td>\n",
       "      <td>129.51</td>\n",
       "      <td>120.17</td>\n",
       "      <td>124.08</td>\n",
       "      <td>4461424.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-03-13 15:00:00</td>\n",
       "      <td>ETHUSD</td>\n",
       "      <td>128.39</td>\n",
       "      <td>128.90</td>\n",
       "      <td>116.06</td>\n",
       "      <td>124.85</td>\n",
       "      <td>7378976.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-03-13 14:00:00</td>\n",
       "      <td>ETHUSD</td>\n",
       "      <td>134.03</td>\n",
       "      <td>137.90</td>\n",
       "      <td>125.50</td>\n",
       "      <td>128.39</td>\n",
       "      <td>3733916.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-03-13 13:00:00</td>\n",
       "      <td>ETHUSD</td>\n",
       "      <td>131.35</td>\n",
       "      <td>140.95</td>\n",
       "      <td>128.99</td>\n",
       "      <td>134.03</td>\n",
       "      <td>9582732.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2020-03-13 12:00:00</td>\n",
       "      <td>ETHUSD</td>\n",
       "      <td>128.93</td>\n",
       "      <td>134.60</td>\n",
       "      <td>126.95</td>\n",
       "      <td>131.35</td>\n",
       "      <td>3906590.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2020-03-13 11:00:00</td>\n",
       "      <td>ETHUSD</td>\n",
       "      <td>132.60</td>\n",
       "      <td>133.17</td>\n",
       "      <td>126.01</td>\n",
       "      <td>128.93</td>\n",
       "      <td>3311080.29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Date  Symbol    Open    High     Low   Close      Volume\n",
       "0 2020-03-13 20:00:00  ETHUSD  129.94  131.82  126.87  128.71  1940673.93\n",
       "1 2020-03-13 19:00:00  ETHUSD  119.51  132.02  117.10  129.94  7579741.09\n",
       "2 2020-03-13 18:00:00  ETHUSD  124.47  124.85  115.50  119.51  4898735.81\n",
       "3 2020-03-13 17:00:00  ETHUSD  124.08  127.42  121.63  124.47  2753450.92\n",
       "4 2020-03-13 16:00:00  ETHUSD  124.85  129.51  120.17  124.08  4461424.71\n",
       "5 2020-03-13 15:00:00  ETHUSD  128.39  128.90  116.06  124.85  7378976.00\n",
       "6 2020-03-13 14:00:00  ETHUSD  134.03  137.90  125.50  128.39  3733916.89\n",
       "7 2020-03-13 13:00:00  ETHUSD  131.35  140.95  128.99  134.03  9582732.93\n",
       "8 2020-03-13 12:00:00  ETHUSD  128.93  134.60  126.95  131.35  3906590.52\n",
       "9 2020-03-13 11:00:00  ETHUSD  132.60  133.17  126.01  128.93  3311080.29"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crypt_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crypt_df.sort_index(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crypt_df['Date']\n",
    "# we can also convert this date column to real datetime data using pd.to_datetime() method\n",
    "crypt_df['Date'] = pd.to_datetime(crypt_df['Date'], format='%Y-%m-%d %I-%p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# day_name() method is used to get the day name of a timestamp\n",
    "crypt_df.loc[0,'Date'].day_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as we use str class on entire series to access all the methods of strings in whole df pr series,\n",
    "# we can also use dt class to access datetime method to a datetime data\n",
    "crypt_df['Date'].dt.day_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crypt_df['Date'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crypt_df['Date'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crypt_df['Date'].max() - crypt_df['Date'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter\n",
    "date_filter = (crypt_df['Date'] >= '2020-03-13')\n",
    "crypt_df.loc[date_filter].sort_values('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crypt_df.set_index('Date',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crypt_df.loc['2020-3-12'].agg(['mean','min','max','median'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# high for the 12-03-2020\n",
    "crypt_df.loc['2020-3-12']['High'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resample the Datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resample the high values and get the max of the hight date wise\n",
    "# passing the D in resample meathod mesn Day wise\n",
    "high_values = crypt_df['High'].resample('D').max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_values['2020-03-12']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_values.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crypt_df.resample('W').agg({'Close':'mean', 'High':'max', 'Low':'min', 'Volume':'sum'})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
